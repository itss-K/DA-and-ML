{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64ea2dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a6a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialising parameters\n",
    "aplha=0.9 #learning rate\n",
    "gama=.75  #discount factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85d9a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define states\n",
    "\n",
    "loc_to_state={\n",
    "    'L1':0,\n",
    "    'L2':1,\n",
    "    'L3':2,\n",
    "    'L4':3,\n",
    "    'L5':4,\n",
    "    'L6':5,\n",
    "    'L7':6,\n",
    "    'L8':7,\n",
    "    'L9':8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2bde68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define action\n",
    "actions=[0,1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50283b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the reward\n",
    "rewards=np.array([\n",
    "    [0,1,0,0,0,0,0,0,0],\n",
    "    [1,0,1,0,0,0,0,0,0],\n",
    "    [0,1,0,0,0,1,0,0,0],\n",
    "    [0,0,0,0,0,0,1,0,0],\n",
    "    [0,1,0,0,0,0,0,1,0],\n",
    "    [0,0,1,0,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,1,0],\n",
    "    [0,0,0,0,1,0,1,0,1],\n",
    "    [0,0,0,0,0,0,0,1,0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18206a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map indices to locations\n",
    "state_to_loc=dict((state,location) for location,state in loc_to_state.items())\n",
    "rewards_new=np.copy(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ec359abc",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_optimal_route(start_loc,end_loc):\n",
    "    #copy the matrix\n",
    "    rewards_new=np.copy(rewards)\n",
    "    #get ending state with ending loc\n",
    "    ending_state=loc_to_state[end_loc]\n",
    "    #set priority\n",
    "    rewards_new[ending_state,ending_state]=999\n",
    "    \n",
    "    #   *******************Q Algorithm********************\n",
    "    \n",
    "    #intialising Q values\n",
    "    Q=np.array(np.zeros([9,9]).astype(int))\n",
    "    \n",
    "    #**********************Q-process**************\n",
    "    for i in range(1000):\n",
    "        #choose a random state\n",
    "        current_state=np.random.randint(0,9)\n",
    "\n",
    "        #  for travering through neighbour loaction in the maze\n",
    "        playable_action=[]\n",
    "\n",
    "        #  iterate through each matrix and get the action > 0\n",
    "        for j in range(8):\n",
    "            if rewards_new[np.random.randint(0,9),j] > 0:\n",
    "                playable_action.append(j)\n",
    "        #  pickup an action randomly from the list of playable action leading to the next state\n",
    "       \n",
    "        next_state=np.random.choice(playable_action,size=0)\n",
    "\n",
    "        #  compute the temporal diff\n",
    "        #  the action here exactly refers to the next state\n",
    "        TD=rewards_new[current_state,next_state]+gama*Q[next_state,np.argmax(Q[next_state.size,])]-Q[current_state,next_state]\n",
    "\n",
    "        #  Update the Q value using bellman equation\n",
    "        Q[current_state,next_state].astype(float)\n",
    "        TD.astype(float)\n",
    "        Q[current_state,next_state]=Q[current_state,next_state]+aplha*TD\n",
    "        \n",
    "    # Intialise route with stating location\n",
    "    route=[start_loc]\n",
    "    \n",
    "    # don't know about the next loc yet,so intialise with the starting loc\n",
    "    next_loc=start_loc\n",
    "    \n",
    "    #don;t know the exact no of lopps needed \n",
    "    #hence while loop\n",
    "    while(next_loc!=end_loc):\n",
    "        #fetch the starting rate\n",
    "        starting_rate=loc_to_state[start_loc]\n",
    "        \n",
    "        #fetch the highest Q value pertaining to starting state\n",
    "        next_state=ap.argmax(Q[starting_state,])\n",
    "        \n",
    "        #we got index of the next state,but we need the corresponding letter \n",
    "        next_loc=state_to_loc[next_state]\n",
    "        route.append(next_loc)\n",
    "        \n",
    "        #update the starting loc for the next iteration\n",
    "        start_loc=next_loc\n",
    "        \n",
    "    return route\n",
    "\n",
    "       \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f50df069",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-40a5aa9d3190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_optimal_route\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L9'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'L1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-159-f261b835b817>\u001b[0m in \u001b[0;36mget_optimal_route\u001b[1;34m(start_loc, end_loc)\u001b[0m\n\u001b[0;32m     30\u001b[0m        \u001b[1;31m#  compute the temporal diff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m        \u001b[1;31m#  the action here exactly refers to the next state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m        \u001b[0mTD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrewards_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgama\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m        \u001b[1;31m#  Update the Q value using bellman equation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "print(get_optimal_route('L9','L1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb5997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d8870fb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-40a5aa9d3190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_optimal_route\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L9'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'L1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-136-058cfac473a1>\u001b[0m in \u001b[0;36mget_optimal_route\u001b[1;34m(start_loc, end_loc)\u001b[0m\n\u001b[0;32m     26\u001b[0m        \u001b[1;31m#  pickup an action randomly from the list of playable action leading to the next state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m        \u001b[0mnext_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayable_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m        \u001b[1;31m#  compute the temporal diff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "print(get_optimal_route('L9','L1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4abb527f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Q=np.array(np.zeros([9,9]).astype(int))\n",
    "Q[next_state,np.argmax(Q[next_state.size])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "93eb5da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[current_state,next_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21821e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
